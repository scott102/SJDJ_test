import os
# ğŸš¨ .env íŒŒì¼ì„ ì½ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from dotenv import load_dotenv
from langchain_community.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_text_splitters import CharacterTextSplitter

# ğŸš¨ .env íŒŒì¼ ë¡œë“œ (ì´ ì½”ë“œê°€ ìˆì–´ì•¼ API í‚¤ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤)
load_dotenv()

# API í‚¤ í™•ì¸ (ë””ë²„ê¹…ìš© - ì‹¤ì œ í‚¤ê°€ ì¶œë ¥ë˜ë©´ ì•ˆ ë˜ë¯€ë¡œ ì¼ë¶€ë§Œ í™•ì¸í•˜ê±°ë‚˜ ì¡´ì¬ ì—¬ë¶€ë§Œ ì²´í¬)
if not os.getenv("OPENAI_API_KEY"):
    print("âŒ ì˜¤ë¥˜: OPENAI_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit(1) # ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

# 1. ë¬¸ì„œ ë¡œë“œ
print("1. ë¬¸ì„œ ë¡œë“œ ì¤‘...")
try:
    loader = TextLoader("website_content.txt", encoding="utf-8")
    documents = loader.load()
except FileNotFoundError:
    print("âŒ ì˜¤ë¥˜: 'website_content.txt' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

# 2. ë¬¸ì„œ ë¶„í•  (ì²­í¬ ë‚˜ëˆ„ê¸°)
# ê¸´ ë¬¸ì„œë¥¼ AIê°€ ì²˜ë¦¬í•˜ê¸° ì‰¬ìš´ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
print("2. ë¬¸ì„œ ë¶„í•  ì¤‘...")
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
texts = text_splitter.split_documents(documents)

# 3. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ (GPT-4o-miniì™€ ì—°ë™í•˜ê¸° ìœ„í•´ OpenAI ëª¨ë¸ ì‚¬ìš©)
print("3. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
try:
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002")
except Exception as e:
    print(f"âŒ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    exit(1)

# 4. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ChromaDB ì‚¬ìš©)
# ì €ì¥ëœ ê²½ë¡œëŠ” './chroma_db' í´ë”ì…ë‹ˆë‹¤.
print("4. ChromaDBì— ë²¡í„° ì €ì¥ ì¤‘...")
try:
    db = Chroma.from_documents(texts, embeddings, persist_directory="./chroma_db")
    print(f"âœ”ï¸ RAG ìƒ‰ì¸ ì™„ë£Œ. ì´ {len(texts)}ê°œì˜ ë¬¸ì„œ ì¡°ê°ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")